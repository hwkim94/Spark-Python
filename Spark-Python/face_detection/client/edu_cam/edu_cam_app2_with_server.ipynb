{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyQt5.QtCore import *\n",
    "from PyQt5.QtGui import *\n",
    "from PyQt5.QtWidgets import *\n",
    "import requests\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "from scipy.ndimage import imread\n",
    "\n",
    "import sys\n",
    "import time\n",
    "import os\n",
    "from copy import deepcopy\n",
    "import ctypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "HWC = (360, 480, 3)\n",
    "WH = (480, 360)\n",
    "IP = \"54.180.93.44\"\n",
    "DB_SERVER_IP = \"http://\" + IP + \":3000/auth\"\n",
    "KAFKA_SERVER_IP = \"http://\" + IP + \":3000/stream\"\n",
    "\n",
    "###############################################################################################################\n",
    "class BeforeLogin(QWidget):\n",
    "    def __init__(self, path=['haarcascades/haarcascade_frontalface_default.xml', 'haarcascades/haarcascade_eye.xml']):\n",
    "        QWindow.__init__(self)\n",
    "        self.path = path\n",
    "        self.token = False\n",
    "        \n",
    "        self.central_layout = QGridLayout()\n",
    "        self.central_widget = QStackedWidget()\n",
    "        self.central_layout.addWidget(self.central_widget)\n",
    "        \n",
    "        lst = [\"ID  : \", \"PW : \"]\n",
    "        self.label_lst, self.edit_lst = self.making_Label_Edit(lst)\n",
    "        pos_lst = [(1,1), (2,1)]\n",
    "        \n",
    "        layout = QGridLayout() \n",
    "        LoginFrame = self.making_Frame(layout, self.label_lst, self.edit_lst, pos_lst)\n",
    "        LoginFrame.setFrameShape(QFrame.StyledPanel)\n",
    "        \n",
    "        LoginButton = QPushButton(\"로그인 하기\")\n",
    "        LoginButton.clicked.connect(self.btnOkClicked)\n",
    "        \n",
    "        LoginLayout = QGridLayout() \n",
    "        LoginLayout.addWidget(LoginFrame)\n",
    "        LoginLayout.addWidget(LoginButton)\n",
    "        \n",
    "        coveringWidget = QWidget()\n",
    "        coveringWidget.setLayout(LoginLayout)\n",
    "        self.central_widget.addWidget(coveringWidget)\n",
    "        self.setLayout(self.central_layout)\n",
    "        \n",
    "        print(\"#\"*60)\n",
    "        print(\"[{}] : program start\".format(time.strftime(\"%Y/%m/%d %H:%M:%S\", time.localtime(time.time()))))\n",
    "        print(\"#\"*60, \"\\n\")\n",
    "        \n",
    "    def btnOkClicked(self):\n",
    "        ID = self.edit_lst[0].text().strip()\n",
    "        PW = self.edit_lst[1].text().strip()\n",
    "        \n",
    "        self.login(ID, PW)\n",
    "\n",
    "    def making_Label_Edit(self, name_lst) :\n",
    "        label_lst = []\n",
    "        edit_lst = []\n",
    "        \n",
    "        for name in name_lst :\n",
    "            label = QLabel(name)\n",
    "            edit = QLineEdit()\n",
    "            \n",
    "            label_lst.append(label)\n",
    "            edit_lst.append(edit)\n",
    "        \n",
    "        return label_lst, edit_lst\n",
    "\n",
    "    def making_Frame(self, layout, label_lst, widget_lst, pos_lst) :\n",
    "        for label, widget, pos in zip(label_lst, widget_lst, pos_lst) :  \n",
    "            layout.addWidget(label, pos[0], pos[1])\n",
    "            layout.addWidget(widget, pos[0], pos[1]+1)\n",
    "            \n",
    "        frame = QFrame()\n",
    "        frame.setLayout(layout)\n",
    "        \n",
    "        return frame\n",
    "    \n",
    "    def login(self, ID, PW) :\n",
    "        print(\"#\"*60)\n",
    "        print(\"[{}] : '{}' try to login\".format(time.strftime(\"%Y/%m/%d %H:%M:%S\", time.localtime(time.time())), ID))\n",
    "        \n",
    "        if self.checkUserDB(ID,PW) :\n",
    "            print(\"[{}] : '{}' success to login\".format(time.strftime(\"%Y/%m/%d %H:%M:%S\", time.localtime(time.time())), ID))\n",
    "            print(\"#\"*60, \"\\n\")\n",
    "            \n",
    "            AfterLayout = self.AfterLogin()\n",
    "            AfterLayout.setToken(self.token)\n",
    "            self.central_widget.addWidget(AfterLayout)\n",
    "            self.central_widget.setCurrentWidget(AfterLayout)\n",
    "        \n",
    "        else :\n",
    "            print(\"[{}] : '{}' fail to login\".format(time.strftime(\"%Y/%m/%d %H:%M:%S\", time.localtime(time.time())), ID))\n",
    "            print(\"#\"*60, \"\\n\")\n",
    "            \n",
    "            QMessageBox.information(self, \"Login failed\", \"check ID & PW\")\n",
    "        \n",
    "    def AfterLogin(self) :\n",
    "        self.afterLoginWidget = AfterLoginWidget(self.token)\n",
    "        return self.afterLoginWidget\n",
    "    \n",
    "    def checkUserDB(self, ID, PW, host=DB_SERVER_IP) :\n",
    "        data = {\"email_id\" : ID, \"password\" : PW}\n",
    "        result = requests.post(host, data=data)\n",
    "        \n",
    "        if \"success\" in result.json() :\n",
    "            self.token = result.json()[\"token\"]\n",
    "            \n",
    "            with open(\"./data/register/registered_info/token.txt\", \"w\") as f:\n",
    "                f.write(self.token)\n",
    "            \n",
    "            return True\n",
    "        else :\n",
    "            return False\n",
    "###############################################################################################################\n",
    "\n",
    "\n",
    "###############################################################################################################\n",
    "class AfterLoginWidget(QWidget):\n",
    "    def __init__(self, token, path=['haarcascades/haarcascade_frontalface_default.xml', 'haarcascades/haarcascade_eye.xml'], interval=3, parent=None):\n",
    "        super().__init__(parent)\n",
    "\n",
    "        self.interval = interval\n",
    "        self.path = path\n",
    "        self.start = False\n",
    "        self.flag_while = False\n",
    "        self.global_flag = [True]\n",
    "        self.isDialog = False\n",
    "        self.dialog_size = (0,0)\n",
    "                \n",
    "        layout = QVBoxLayout()\n",
    "        self.msg = QLabel(\"ready for detection\")\n",
    "        self.ready_detection()\n",
    "\n",
    "        layout = QVBoxLayout()\n",
    "        self.RegisterButton = QPushButton('Register')\n",
    "        self.RunButton = QPushButton('Start')\n",
    "        self.ExitButton = QPushButton('Stop')\n",
    "\n",
    "        self.RegisterButton.clicked.connect(self.registerClicked)\n",
    "        self.RunButton.clicked.connect(self.runClicked)\n",
    "        self.ExitButton.clicked.connect(self.stopClicked)\n",
    "\n",
    "        layout.addWidget(self.RegisterButton)\n",
    "        layout.addWidget(self.msg)\n",
    "        layout.addWidget(self.RunButton)\n",
    "        layout.addWidget(self.ExitButton)\n",
    "        self.setLayout(layout)\n",
    "        \n",
    "        self.detectionThread = detectionThread(self.global_flag)\n",
    "        \n",
    "    def setToken(self, token) :\n",
    "        self.token = token\n",
    "        self.detectionThread.setToken(token)\n",
    "        \n",
    "    def registerClicked(self) :\n",
    "        if (not self.start) and self.flag_while:\n",
    "            params = [self.video_capture, self.face_cascade, self.eyes_cascade, \n",
    "                      self.msg, self.interval, self.flag_while]\n",
    "            self.openRegisterThread = openRegisterThread(params, self)\n",
    "            self.openRegisterThread.start()\n",
    "            \n",
    "            if self.dialog_size[0] !=0 :\n",
    "                print(\"#\"*60)\n",
    "                print(\"[{}] : try to register\".format(time.strftime(\"%Y/%m/%d %H:%M:%S\", time.localtime(time.time()))))\n",
    "                print(\"dialog size has {}\".format(self.dialog_size))\n",
    "                print(\"#\"*60, \"\\n\")\n",
    "                self.registerDialog = registerDialog(params, self.dialog_size, self)\n",
    "                self.registerDialog.show()\n",
    "                self.dialog_size = (0,0)\n",
    "                self.isDialog = True\n",
    "                \n",
    "            else :\n",
    "                print(\"#\"*60)\n",
    "                print(\"[{}] : fail to register -- ready for register\".format(time.strftime(\"%Y/%m/%d %H:%M:%S\", time.localtime(time.time()))))\n",
    "                print(\"#\"*60, \"\\n\")\n",
    "                QMessageBox.information(self, \"Register failed\", \"ready for register, try again\")\n",
    "        \n",
    "        else : \n",
    "            print(\"#\"*60)\n",
    "            print(\"#\"*60, \"\\n\")\n",
    "            QMessageBox.information(self, \"Register failed\", \"stop the detection first\")\n",
    "        \n",
    "    def runClicked(self) :\n",
    "        self.global_flag[0] = True\n",
    "\n",
    "        if (not self.start) and self.flag_while:\n",
    "            self.start = True\n",
    "            \n",
    "            print(\"#\"*60)\n",
    "            print(\"[{}] : detection start\".format(time.strftime(\"%Y/%m/%d %H:%M:%S\", time.localtime(time.time()))))\n",
    "            print(\"#\"*60, \"\\n\")\n",
    "            \n",
    "            \n",
    "            params = [self.video_capture, self.face_cascade, self.eyes_cascade, \n",
    "                      self.msg, self.interval, self.flag_while]\n",
    "\n",
    "            self.detectionThread.setParams(params)\n",
    "            self.detectionThread.setRecognizer(self.recognizer)\n",
    "            self.detectionThread.start()\n",
    "    \n",
    "    def stopClicked(self) : \n",
    "        self.global_flag[0] = False\n",
    "        \n",
    "        if self.start :\n",
    "            self.start = False\n",
    "\n",
    "            print(\"\")\n",
    "            print(\"#\"*60)\n",
    "            print(\"[{}] : detection stopped\".format(time.strftime(\"%Y/%m/%d %H:%M:%S\", time.localtime(time.time()))))\n",
    "            print(\"#\"*60, \"\\n\")\n",
    "\n",
    "            self.msg.setText(\"ready for detection\")\n",
    " \n",
    "    def ready_detection(self) : \n",
    "        self.face_cascade = cv2.CascadeClassifier(self.path[0])\n",
    "        self.eyes_cascade = cv2.CascadeClassifier(self.path[1])\n",
    "        \n",
    "        self.recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "            \n",
    "        self.video_capture = cv2.VideoCapture(0)\n",
    "        _, first_frame = self.video_capture.read()\n",
    "\n",
    "        print(\"#\"*60)\n",
    "        try : \n",
    "            if not first_frame :\n",
    "                print(\"[{}] : camera is not conntected\".format(time.strftime(\"%Y/%m/%d %H:%M:%S\", time.localtime(time.time()))))\n",
    "                self.flag_while = False\n",
    "        except :\n",
    "            print(\"[{}] : camera is conntected\".format(time.strftime(\"%Y/%m/%d %H:%M:%S\", time.localtime(time.time()))))\n",
    "            self.flag_while = True\n",
    "        print(\"#\"*60, \"\\n\")\n",
    "###############################################################################################################\n",
    "\n",
    "\n",
    "###############################################################################################################\n",
    "class detectionThread(QThread) :\n",
    "    def __init__(self, global_flag):\n",
    "        QThread.__init__(self)\n",
    "        self.global_idx = 0\n",
    "        self.global_flag = global_flag\n",
    "        \n",
    "        self.img_count = 0\n",
    "        self.face_count = 0\n",
    "        self.eye_count = 0\n",
    "        self.confidence = []\n",
    "        self.coord = []\n",
    "        \n",
    "        self.change_cnt = 0\n",
    "        self.change_conf_lst = []\n",
    "        self.yml_ver = 1\n",
    "        self.rd_flag = False\n",
    "        \n",
    "        self.sThread = saveThread()\n",
    "        self.rdThread = reg_detThread()\n",
    "\n",
    "    def __del__(self):\n",
    "        self.flag_while = False\n",
    "        self.wait()\n",
    "        \n",
    "    def setParams(self, params) :\n",
    "        self.video_capture = params[0]\n",
    "        self.face_cascade = params[1]\n",
    "        self.eyes_cascade = params[2]\n",
    "        self.msg = params[3]\n",
    "        self.interval = params[4]\n",
    "        self.flag_while = params[5]\n",
    "        \n",
    "    def setRecognizer(self, recognizer) :\n",
    "        self.recognizer = recognizer\n",
    "        \n",
    "    def setToken(self, token) :\n",
    "        self.token = token\n",
    "        self.sThread.setToken(token)\n",
    "        \n",
    "    def mean(self, lst) :\n",
    "        if len(lst) == 0 :\n",
    "            return 0\n",
    "        \n",
    "        return sum(lst) / len(lst)\n",
    "\n",
    "    def run(self):\n",
    "        self.face_detection()\n",
    "    \n",
    "    def face_detection(self) :\n",
    "        self.recognizer.read(\"./data/register/registered_info/train1.yml\")\n",
    "        start_time = time.time()\n",
    "        append_cnt = 0\n",
    "        \n",
    "        label = 0\n",
    "        confidence = 0\n",
    "        \n",
    "        # 재학습용 param\n",
    "        re_img_cnt = 0\n",
    "        re_face_cnt = 0\n",
    "        re_eye_cnt = 0\n",
    "        re_train_img_cnt = []\n",
    "        re_train_face_cnt = []\n",
    "        re_train_eye_cnt = []\n",
    "        \n",
    "        # detection\n",
    "        while self.flag_while and self.global_flag[0]:\n",
    "            read, frame = self.video_capture.read()\n",
    "            frame = cv2.resize(frame, WH)\n",
    "\n",
    "            if not read :\n",
    "                continue\n",
    "            \n",
    "            if self.rd_flag :\n",
    "                re_img_cnt += 1\n",
    "                \n",
    "            self.img_count +=  1    \n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            flag, detected_frame, coords = self.detect(gray, frame)\n",
    "            \n",
    "            # 얼굴이 인식되지 않았을 경우\n",
    "            if not flag[0] :\n",
    "                #print(\"[{}] : (1) face and eye are not detected\".format(time.strftime(\"%Y/%m/%d %H:%M:%S\", time.localtime(time.time()))))\n",
    "                self.msg.setText(\"(msg1) face and eye are not detected\")\n",
    "                self.face_count += 0\n",
    "            \n",
    "            # 얼굴이 인식되었을 경우\n",
    "            else :\n",
    "                self.face_count += 1\n",
    "                label, confidence = self.recognizer.predict(detected_frame)\n",
    "                coord = self.size_filter(coords[0])\n",
    "                self.confidence.append(confidence)\n",
    "                self.coord.append(coord[0])\n",
    "                \n",
    "                if self.rd_flag :\n",
    "                    re_face_cnt += 1\n",
    "                \n",
    "                # 눈이 인식되지 않았을 경우\n",
    "                if not flag[1] :\n",
    "                    #print(\"[{}] : (2) face is detected, but eye is not detected, --confidence {:.1f}\".format(time.strftime(\"%Y/%m/%d %H:%M:%S\", time.localtime(time.time())), confidence))\n",
    "                    self.msg.setText(\"(msg2) face is detected, but eye is not detected\")\n",
    "                    self.eye_count += 0\n",
    "                \n",
    "                # 눈이 인식되었을 경우\n",
    "                else : \n",
    "                    #print(\"[{}] : (3) face and eye are detected, --confidence {:.1f}\".format(time.strftime(\"%Y/%m/%d %H:%M:%S\", time.localtime(time.time())), confidence))\n",
    "                    self.msg.setText(\"(msg3) face and eye are detected\")\n",
    "                    self.eye_count += 1\n",
    "                    \n",
    "                    if self.rd_flag :\n",
    "                        re_eye_cnt += 1\n",
    "                \n",
    "                # 재학습되는 경우\n",
    "                if self.rd_flag :\n",
    "                    self.rdThread.add(detected_frame, coord[0])\n",
    "                    \n",
    "                    if self.rdThread.data_size == 200 :\n",
    "                        print(\"-\"*90)\n",
    "                        print(\"[{}] : re-train starts\".format(time.strftime(\"%Y/%m/%d %H:%M:%S\", time.localtime(time.time()))))\n",
    "                        print(\"-\"*90)\n",
    "                        \n",
    "                        self.rdThread.setVersion(self.yml_ver)\n",
    "                        self.rdThread.setDThread(self)\n",
    "                        self.rdThread.setCnt(re_train_img_cnt, re_train_face_cnt, re_train_eye_cnt)\n",
    "                        self.rdThread.start()\n",
    "                        \n",
    "                        re_img_cnt = 0\n",
    "                        re_face_cnt = 0\n",
    "                        re_eye_cnt = 0\n",
    "                        re_train_img_cnt = []\n",
    "                        re_train_face_cnt = []\n",
    "                        re_train_eye_cnt = []\n",
    "                        self.rd_flag = False \n",
    "                    \n",
    "            now = time.time()\n",
    "            \n",
    "            # 재학습하는 경우 2초마다 count 정보 추가\n",
    "            if self.rd_flag and now - start_time >= 2:\n",
    "                re_train_img_cnt.append(re_img_cnt)\n",
    "                re_train_face_cnt.append(re_face_cnt)\n",
    "                re_train_eye_cnt.append(re_eye_cnt)\n",
    "                \n",
    "                re_img_cnt = 0\n",
    "                re_face_cnt = 0\n",
    "                re_eye_cnt = 0\n",
    "                start_time = now\n",
    "            \n",
    "            # 5초마다 데이터 stack\n",
    "            if now - start_time >= 5 :\n",
    "                self.sThread.setInfo(self.img_count, self.face_count, self.eye_count, deepcopy(self.confidence), deepcopy(self.coord), now)\n",
    "                self.change_conf_lst.append(self.mean(self.confidence))\n",
    "                \n",
    "                self.img_count = 0\n",
    "                self.face_count = 0\n",
    "                self.eye_count = 0\n",
    "                self.confidence = []\n",
    "                self.coord = []\n",
    "                \n",
    "                start_time = now\n",
    "                append_cnt +=1\n",
    "                \n",
    "                # 재학습 여부 판단\n",
    "                conf_mean = self.mean(self.change_conf_lst)\n",
    "                if conf_mean >= 60 and (not self.rd_flag) :\n",
    "                    self.change_cnt += 1\n",
    "                        \n",
    "                    if self.change_cnt == 12 :\n",
    "                        self.yml_ver += 1\n",
    "                        self.change_cnt = 0 \n",
    "                            \n",
    "                        dir_lst = os.listdir(\"./data/register/registered_info\")\n",
    "                        yml = \"train\" + str(self.yml_ver) + \".yml\"\n",
    "                            \n",
    "                        if yml in dir_lst :\n",
    "                            self.recognizer.read(\"./data/register/registered_info/\" + yml)\n",
    "                        else : \n",
    "                            self.rd_flag = True\n",
    "\n",
    "                elif conf_mean < 20 and (not self.rd_flag) :\n",
    "                    self.change_cnt = 0\n",
    "                \n",
    "                # 저장\n",
    "                if append_cnt == 12 :\n",
    "                    self.sThread.setIndex(self.global_idx)\n",
    "                    self.sThread.start()\n",
    "                    self.global_idx += 1\n",
    "                    append_cnt = 0\n",
    "                       \n",
    "        self.msg.setText(\"ready for detection\")\n",
    "        self.imgs = []\n",
    "        self.img_count = 0\n",
    "        self.face_count = 0\n",
    "        self.eye_count = 0\n",
    "\n",
    "    def detect(self, gray, frame):\n",
    "        faces = self.face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "        face = self.size_filter(faces)\n",
    "        roi_gray = []\n",
    "\n",
    "        for (x,y,w,h) in face:\n",
    "            cv2.rectangle(frame, (x,y), (x+w, y+h), (255,0,0), 2)\n",
    "\n",
    "            roi_gray = gray[y:y+h, x:x+w]\n",
    "            roi_color = frame[y:y+h, x:x+w]\n",
    "\n",
    "            eyes = self.eyes_cascade.detectMultiScale(roi_gray, 1.1, 3)\n",
    "            for (ex, ey, ew, eh) in eyes:\n",
    "                cv2.rectangle(roi_color, (ex,ey), (ex+ew, ey+eh), (0, 255, 0), 2)\n",
    "                    \n",
    "        if len(faces) == 0 :\n",
    "            flag = [False, False]\n",
    "            eyes = []\n",
    "                \n",
    "        elif len(faces) > 0 and len(eyes) == 0 :\n",
    "            flag = [True, False]\n",
    "                \n",
    "        else : \n",
    "            flag = [True, True]\n",
    "            \n",
    "        coord = [faces, eyes]\n",
    "        return flag, roi_gray, coord \n",
    "    \n",
    "    def size_filter(self, coords) :\n",
    "        if len(coords) == 0 :\n",
    "            return []\n",
    "        \n",
    "        size = 0 \n",
    "        best_coord = np.array([0,0,0,0])\n",
    "\n",
    "        for coord in coords :\n",
    "            now = coord[2]*coord[3]\n",
    "            if now > size :\n",
    "                size = now\n",
    "                best_coord = coord\n",
    "\n",
    "        return [best_coord]\n",
    "    \n",
    "class saveThread(QThread) :\n",
    "    def __init__(self):\n",
    "        QThread.__init__(self)\n",
    "        self.idx = -1\n",
    "        \n",
    "        self.img_count = []\n",
    "        self.face_count = []\n",
    "        self.eye_count = []\n",
    "        self.confidence = []\n",
    "        self.coord = []\n",
    "        self.time = []\n",
    "        \n",
    "    def __del__(self):\n",
    "        self.img = []\n",
    "        self.wait()\n",
    "        \n",
    "    def setInfo(self, c_img, c_face, c_eye, conf, coord, now) :\n",
    "        self.img_count.append(c_img)\n",
    "        self.face_count.append(c_face)\n",
    "        self.eye_count.append(c_eye)\n",
    "        \n",
    "        mean = self.mean(conf)\n",
    "        self.confidence.append(mean)\n",
    "\n",
    "        x = self.mean([c[0] for c in coord])\n",
    "        y = self.mean([c[1] for c in coord])\n",
    "        wh = self.mean([c[2] for c in coord])\n",
    "        self.coord.append([x, y, wh, wh])\n",
    "        \n",
    "        self.time.append(time.strftime(\"%Y/%m/%d %H:%M:%S\", time.localtime(now)))\n",
    "        \n",
    "        print(\"-\"*90)\n",
    "        print(\"[{}] : values for aggreagation are added --length {}\".format(time.strftime(\"%Y/%m/%d %H:%M:%S\", time.localtime(time.time())), len(self.img_count)))\n",
    "        print(\"{}, {}, {}, {:.3f}, {:.3f}, {:.3f}, {:.3f}, {:.3f}\".format(c_img, c_face, c_eye, mean, x, y, wh, wh))\n",
    "        print(\"-\"*90)\n",
    "        \n",
    "    def setIndex(self, idx) :\n",
    "        self.idx = idx\n",
    "        \n",
    "    def setToken(self, token) :\n",
    "        self.token = token\n",
    "    \n",
    "    def run(self):\n",
    "        self.save()\n",
    "        \n",
    "    def mean(self, lst) :\n",
    "        if len(lst) == 0 :\n",
    "            return 0\n",
    "        \n",
    "        return sum(lst) / len(lst)\n",
    "        \n",
    "    def save(self) :\n",
    "        x = [c[0] for c in self.coord]\n",
    "        y = [c[1] for c in self.coord]\n",
    "        wh = [c[2] for c in self.coord]\n",
    "        \n",
    "        with open(\"./data/detect/detected_info/detected_data{}.txt\".format(self.idx), \"w\") as f:\n",
    "            contents =  \"\"\n",
    "            idx = len(self.confidence)\n",
    "            \n",
    "            for img, face, eye, conf, x, y, wh, t in zip(self.img_count, self.face_count, self.eye_count, self.confidence, x, y, wh, self.time): \n",
    "                contents += \"{}, {}, {}, {:.3f}, {:.3f}, {:.3f}, {:.3f}, {:.3f}, {}\".format(img, face, eye, conf, x, y, wh, wh,t)\n",
    "                \n",
    "                idx -= 1\n",
    "                if idx != 0 :  \n",
    "                    contents += \"\\n\"\n",
    "            f.write(contents)\n",
    "            \n",
    "        data = {\"msg\" : contents, \"token\" : self.token}\n",
    "        result = requests.post(KAFKA_SERVER_IP, data=data)\n",
    "            \n",
    "        self.img_count = []\n",
    "        self.face_count = []\n",
    "        self.eye_count = []\n",
    "        self.confidence = []\n",
    "        self.coord = []\n",
    "        self.time = []\n",
    "            \n",
    "        print(\"-\"*90)\n",
    "        print(\"[{}] : saving is finished\".format(time.strftime(\"%Y/%m/%d %H:%M:%S\", time.localtime(time.time()))))\n",
    "        print(\"-\"*90)\n",
    "        \n",
    "class reg_detThread(QThread) :\n",
    "    def __init__(self):\n",
    "        QThread.__init__(self)\n",
    "        self.frame = []\n",
    "        self.coords = []\n",
    "        self.eye = 0\n",
    "        self.data_size = 0\n",
    "        self.ver = -1\n",
    "        \n",
    "    def __del__(self) : \n",
    "        self.wait()\n",
    "    \n",
    "    def add(self, detected_frame, coords) :\n",
    "        self.frame.append(detected_frame)\n",
    "        self.coords.append(coords)\n",
    "        self.data_size += 1\n",
    "    \n",
    "    def setVersion(self, ver) :\n",
    "        self.ver = ver\n",
    "    \n",
    "    def setDThread(self, dThread) :\n",
    "        self.dThread = dThread\n",
    "    \n",
    "    def setCnt(self, img, face, eye) :\n",
    "        cnt = [(str(i), str(f), str(c)) for i, f, c in zip(img, face, eye)]\n",
    "        self.cnt = [\", \".join(x) for x in cnt]\n",
    "        \n",
    "    def run(self):\n",
    "        self.register_with_detect()\n",
    "\n",
    "    def register_with_detect(self) :\n",
    "        for idx, img in enumerate(self.frame[:100]) :\n",
    "            cv2.imwrite(\"./data/register/registered_png/register_{}.png\".format(idx), img, [])\n",
    "        \n",
    "        labels = self.make_labels(self.frame[:100])\n",
    "        \n",
    "        recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "        recognizer.train(self.frame[:100], labels)\n",
    "        recognizer.save(\"./data/register/registered_info/train\" + str(self.ver) +\".yml\")\n",
    "        recognizer.read(\"./data/register/registered_info/train\" + str(self.ver) +\".yml\")\n",
    "        \n",
    "        self.coord = self.text_rectangle(self.coords)\n",
    "        with open(\"./data/register/registered_info/rectangle_coord.txt\", \"w\") as f:\n",
    "            f.write(\"\\n\".join(self.coord))\n",
    "            \n",
    "        with open(\"./data/register/registered_info/count.txt\", \"w\") as f:\n",
    "            f.write(\"\\n\".join(self.cnt))\n",
    "            \n",
    "        with open(\"./data/register/registered_info/train_datetime.txt\", \"w\") as f:\n",
    "            f.write(str(time.strftime(\"%Y/%m/%d %H:%M\", time.localtime(time.time()))))\n",
    "            \n",
    "        confidence = []\n",
    "        contents=\"\"\n",
    "        for frame in self.frame[100:] :\n",
    "            confidence.append(recognizer.predict(frame)[1])\n",
    "            \n",
    "        with open(\"./data/register/registered_info/confidence.txt\", \"w\") as f:\n",
    "            f.write(\"\\n\".join([str(conf) for conf in confidence]))\n",
    "            \n",
    "        self.frame = []\n",
    "        self.coords = []\n",
    "        self.eye = 0\n",
    "        self.ver = -1\n",
    "        self.data_size = 0\n",
    "        \n",
    "        self.dThread.recognizer = recognizer\n",
    "        print(\"-\"*90)\n",
    "        print(\"[{}] : re-train finished\".format(time.strftime(\"%Y/%m/%d %H:%M:%S\", time.localtime(time.time()))))\n",
    "        print(\"-\"*90)\n",
    "        \n",
    "        self.quit()\n",
    "    \n",
    "    def mean(self, lst) :\n",
    "        if len(lst) == 0 :\n",
    "            return 0\n",
    "        \n",
    "        return sum(lst) / len(lst)\n",
    "        \n",
    "    def text_rectangle(self, coords) :\n",
    "        result = []\n",
    "        for lst in coords :\n",
    "            result.append(\", \".join([str(x) for x in lst]))\n",
    "            \n",
    "        return result\n",
    "        \n",
    "    def make_labels(self, images) :\n",
    "        labels = []\n",
    "\n",
    "        length = len(images)\n",
    "        for idx in range(length) :\n",
    "            labels.append(1)\n",
    "\n",
    "        return np.array(labels)\n",
    "        \n",
    "    def making_gray(self, images) :\n",
    "        result = []\n",
    "\n",
    "        for image in images :\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            result.append(gray)\n",
    "\n",
    "###############################################################################################################\n",
    "\n",
    "    \n",
    "###############################################################################################################\n",
    "class openRegisterThread(QThread) : \n",
    "    def __init__(self, params, widget):\n",
    "        QThread.__init__(self)\n",
    "        \n",
    "        self.widget = widget\n",
    "        self.setParams(params)\n",
    "        self.params = params\n",
    "\n",
    "    def __del__(self):\n",
    "        self.wait()\n",
    "        \n",
    "    def setParams(self, params) :\n",
    "        self.video_capture = params[0]\n",
    "        self.face_cascade = params[1]\n",
    "        self.eyes_cascade = params[2]\n",
    "        self.msg = params[3]\n",
    "        self.interval = params[4]\n",
    "        self.flag_while = params[5]\n",
    "\n",
    "    def run(self):\n",
    "        self.get_size()\n",
    "    \n",
    "    def get_size(self) :\n",
    "        read, frame = self.video_capture.read()\n",
    "        h,w,c = HWC\n",
    "        \n",
    "        self.widget.dialog_size = (w,h)\n",
    "        with open(\"./data/register/registered_info/cam_size.txt\", \"w\") as f:\n",
    "            f.write(str(w) + \", \" + str(h))\n",
    "            \n",
    "        self.quit()\n",
    "\n",
    "class registerDialog(QDialog):\n",
    "    def __init__(self, params, size, widget) :\n",
    "        QDialog.__init__(self)  \n",
    "        self.params = params\n",
    "        self.setWindowTitle('Register')\n",
    "        self.resize(size[0], size[1])\n",
    "        self.widget = widget\n",
    "        \n",
    "        self.start = False\n",
    "        \n",
    "        self.registerThread = registerThread()\n",
    "        self.registerThread.setParams(params)\n",
    "        self.registerThread.setDialog(self)\n",
    "\n",
    "        self.imageLabel = QLabel()\n",
    "        self.RunButton = QPushButton('Start')\n",
    "        self.ExitButton = QPushButton('Stop and Exit')\n",
    "\n",
    "        self.RunButton.clicked.connect(self.runClicked)\n",
    "        self.ExitButton.clicked.connect(self.stopClicked)\n",
    "\n",
    "        self.layout = QVBoxLayout()\n",
    "        self.layout.addWidget(self.imageLabel)\n",
    "        self.layout.addWidget(self.RunButton)\n",
    "        self.layout.addWidget(self.ExitButton)\n",
    "        \n",
    "        self.registerThread.setImageLabel(self.imageLabel)\n",
    "        self.setLayout(self.layout)\n",
    "        \n",
    "        self.registerThread.start()\n",
    "        self.start = False\n",
    "        \n",
    "    def setParams(self, params) : \n",
    "        self.video_capture = params[0]\n",
    "        self.face_cascade = params[1]\n",
    "        self.eyes_cascade = params[2]\n",
    "        self.msg = params[3]\n",
    "        self.interval = params[4]\n",
    "        self.flag_while = params[5]\n",
    "        \n",
    "        self.registerThread.setParams(params)\n",
    "        \n",
    "    def runClicked(self) :\n",
    "        if not self.start :\n",
    "            print(\"#\"*60)\n",
    "            print(\"[{}] : start register\".format(time.strftime(\"%Y/%m/%d %H:%M:%S\", time.localtime(time.time()))))\n",
    "            print(\"#\"*60, \"\\n\")\n",
    "            print(\"[{}] : step1 start\".format(time.strftime(\"%Y/%m/%d %H:%M:%S\", time.localtime(time.time()))))\n",
    "\n",
    "            self.registerThread.start_register = True\n",
    "            self.registerThread.start_saving = False\n",
    "            self.registerThread.finish_saving = [False]\n",
    "            self.registerThread.detected_lst = []\n",
    "            self.registerThread.coord_lst = []\n",
    "            self.registerThread.confidence_lst = []\n",
    "            self.registerThread.eye_count = 0\n",
    "            self.start = True\n",
    "        \n",
    "    def stopClicked(self) :\n",
    "        if self.start : \n",
    "            print(\"#\"*60)\n",
    "            print(\"[{}] : stop register\".format(time.strftime(\"%Y/%m/%d %H:%M:%S\", time.localtime(time.time()))))\n",
    "            print(\"#\"*60, \"\\n\")\n",
    "\n",
    "            self.registerThread.start_register = False\n",
    "            self.registerThread.start_saving = False\n",
    "            self.registerThread.finish_saving = [False]\n",
    "            self.registerThread.detected_lst = []\n",
    "            self.registerThread.coord_lst = []\n",
    "            self.registerThread.confidence_lst = []\n",
    "            self.registerThread.eye_count = 0\n",
    "            self.start = False\n",
    "            \n",
    "    def closeEvent(self, event):\n",
    "        self.registerThread.go_flag = False\n",
    "        self.registerThread.quit()\n",
    "        self.widget.isDialog = False\n",
    "        \n",
    "        print(\"#\"*60)\n",
    "        print(\"[{}] : success to register\".format(time.strftime(\"%Y/%m/%d %H:%M:%S\", time.localtime(time.time()))))\n",
    "        print(\"#\"*60, \"\\n\")\n",
    "                \n",
    "        event.accept()\n",
    "###############################################################################################################\n",
    "\n",
    "\n",
    "###############################################################################################################\n",
    "class registerThread(QThread) :\n",
    "    def __init__(self):\n",
    "        QThread.__init__(self)\n",
    "        self.imgs = []\n",
    "        self.go_flag = True\n",
    "        self.start_register = False\n",
    "        self.coord_lst = []\n",
    "        self.detected_lst = []\n",
    "        self.confidence_lst = []\n",
    "        \n",
    "        self.img_count = 0\n",
    "        self.face_count = 0\n",
    "        self.eye_count = 0\n",
    "        self.count = []\n",
    "        \n",
    "        self.step = [1]\n",
    "        self.start_saving = False\n",
    "        self.finish_saving = [False]\n",
    "        \n",
    "        self.recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "        \n",
    "    def __del__(self):\n",
    "        self.wait()\n",
    "        self.go_flag = False\n",
    "        \n",
    "    def setParams(self, params) :\n",
    "        self.video_capture = params[0]\n",
    "        self.face_cascade = params[1]\n",
    "        self.eyes_cascade = params[2]\n",
    "        self.msg = params[3]\n",
    "        self.interval = params[4]\n",
    "        self.flag_while = params[5]\n",
    "        \n",
    "    def setDialog(self, dialog) :\n",
    "        self.dialog = dialog\n",
    "        \n",
    "    def setImageLabel(self, imageLabel) :\n",
    "        self.imageLabel = imageLabel\n",
    "        self.imageLabel.setAlignment(Qt.AlignCenter)\n",
    "        self.imageLabel.setScaledContents(True)\n",
    "        self.imageLabel.setMinimumSize(1,1)\n",
    "\n",
    "    def run(self):\n",
    "        self.face_register()\n",
    "    \n",
    "    def face_register(self) :\n",
    "        start_time = 0\n",
    "        font = cv2.FONT_HERSHEY_PLAIN\n",
    "        color = (0,0,0)\n",
    "        stroke = 2\n",
    "       \n",
    "        while self.go_flag :\n",
    "            if self.start_register :\n",
    "                read, frame = self.video_capture.read()\n",
    "                frame = cv2.resize(frame, WH)\n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "                h, w, c = HWC\n",
    "                end_time = time.time()\n",
    "\n",
    "                # step1 : 얼굴이 인식되는 장소와 bounding box를 찾기\n",
    "                # 요청 : 정면의 카메라를 보고 있어주세요. (촬영횟수 count)\n",
    "                if self.step[0] == 1 :\n",
    "                    flag, detected_frame, coords, eye = self.detect(gray, frame, (255,0,0))\n",
    "                    cv2.circle(frame, (w//2, h//2), 3, (255,0,0), -1)\n",
    "                    \n",
    "                    if len(coords) != 0 :\n",
    "                        check = self.check_include_center(coords[0], w, h)\n",
    "                    else :\n",
    "                        check = False\n",
    "                        \n",
    "                    if flag and check:\n",
    "                        name = \"place at center of screen, complete {:.1f}%\".format(len(self.coord_lst)/50*100)\n",
    "                        cv2.putText(frame, name, (20, 20), font, 1,(255,0,0), stroke, cv2.LINE_AA)\n",
    "                        self.coord_lst.append(coords[0])\n",
    "\n",
    "                        if len(self.coord_lst) == 50 :\n",
    "                            print(\"[{}] : step1 finished\".format(time.strftime(\"%Y/%m/%d %H:%M:%S\", time.localtime(time.time()))))\n",
    "                            print(\"[{}] : step2 start\".format(time.strftime(\"%Y/%m/%d %H:%M:%S\", time.localtime(time.time()))))\n",
    "                            self.set_rectangle(self.coord_lst)\n",
    "                            self.step[0] += 1\n",
    "\n",
    "                            start_time = time.time()\n",
    "\n",
    "                    elif flag and not check:\n",
    "                        name = \"place at center of screen, complete {:.1f}%\".format(len(self.coord_lst)/50*100)\n",
    "                        cv2.putText(frame, name, (20, 20), font, 1,(255,0,0), stroke, cv2.LINE_AA)\n",
    "\n",
    "                    elif not flag:\n",
    "                        name = \"fail to detect face,       complete {:.1f}%\".format(len(self.coord_lst)/50*100)\n",
    "                        cv2.putText(frame, name, (20, 20), font, 1,(255,0,0), stroke, cv2.LINE_AA)\n",
    "\n",
    "                # step2 : 얼굴이 인식되는 장소에 bounding box를 그리고 얼굴을 인식하여 사진 모으기(50~100)\n",
    "                # 요청  : 정면의 카메라를 보고 있어주세요. (촬영횟수 count)\n",
    "                #         만약 사각형이 얼굴을 찾지 못한다면, 다시 시작해주세요.\n",
    "                elif self.step[0] == 2 :                       \n",
    "                    flag, detected_frame, coords, eye = self.detect(gray, frame, (0,0,255))\n",
    "                    self.img_count += 1\n",
    "                    \n",
    "                    if len(coords) != 0 :\n",
    "                        self.face_count += 1\n",
    "                        area, check = self.check_overlap(coords[0])\n",
    "                    else :\n",
    "                        area = 0\n",
    "                        check = False\n",
    "                        \n",
    "\n",
    "                    if end_time - start_time >= 5 and  check:\n",
    "                        detected_frame = cv2.cvtColor(detected_frame, cv2.COLOR_RGB2BGR)\n",
    "                        self.detected_lst.append(detected_frame)\n",
    "                        \n",
    "                        if eye : \n",
    "                            self.eye_count += 1\n",
    "                        \n",
    "                    name = \"mathcing 80% rectangle,    complete {:.1f}%\".format(len(self.detected_lst)/100*100)\n",
    "                    cv2.putText(frame, name, (20, 20), font, 1,(255,0,0), stroke, cv2.LINE_AA)\n",
    "                    cv2.rectangle(frame, (self.x, self.y), (self.x+self.w, self.y+self.h), (255,0,0), 2)\n",
    "\n",
    "                    if self.img_count == 50 :\n",
    "                        self.count.append((str(self.img_count), str(self.face_count), str(self.eye_count)))\n",
    "                        self.img_count = 0\n",
    "                        self.face_count = 0\n",
    "                        self.eye_count = 0\n",
    "                    \n",
    "                    if len(self.detected_lst) == 100 :\n",
    "                        print(\"[{}] : step2 finished\".format(time.strftime(\"%Y/%m/%d %H:%M:%S\", time.localtime(time.time()))))\n",
    "                        print(\"[{}] : step3 start\".format(time.strftime(\"%Y/%m/%d %H:%M:%S\", time.localtime(time.time()))))\n",
    "                        self.step[0] += 1\n",
    "\n",
    "                # step3 : 저장\n",
    "                elif self.step[0] == 3 :\n",
    "                    if not self.start_saving :\n",
    "                        tThread = trainThread(self.detected_lst, self.count)\n",
    "                        tThread.setStep(self.step)\n",
    "                        tThread.setFlag(self.finish_saving)\n",
    "                        tThread.setRecognizer(self.recognizer)\n",
    "                        tThread.setCoord(self.coord_lst)\n",
    "                        tThread.start()\n",
    "                        self.start_saving = True\n",
    "                        \n",
    "                    if self.finish_saving[0] :\n",
    "                        self.step[0] += 1\n",
    "                        start_time = time.time()\n",
    "                        self.recognizer.read(\"./data/register/registered_info/train1.yml\")\n",
    "                        \n",
    "                        print(\"[{}] : step3 finished\".format(time.strftime(\"%Y/%m/%d %H:%M:%S\", time.localtime(time.time()))))\n",
    "                        print(\"[{}] : step4 start\".format(time.strftime(\"%Y/%m/%d %H:%M:%S\", time.localtime(time.time()))))\n",
    "                        \n",
    "                    name = \"saving register result... wait please\"\n",
    "                    cv2.putText(frame, name, (20, 20), font, 1,(255,0,0), stroke, cv2.LINE_AA)\n",
    "                    cv2.rectangle(frame, (self.x, self.y), (self.x+self.w, self.y+self.h), (255,0,0), 2)\n",
    "                    \n",
    "                # step4 : confidence 확인\n",
    "                elif self.step[0] == 4 : \n",
    "                    flag, detected_frame, coords, eye = self.detect(gray, frame, (0,0,255))                    \n",
    "                    \n",
    "                    if len(coords) != 0 :\n",
    "                        coord = coords[0]\n",
    "                        area, check = self.check_overlap(coord)\n",
    "                    else :\n",
    "                        area = 0\n",
    "                        check = False\n",
    "                        \n",
    "                    if end_time - start_time >= 5 and  check:\n",
    "                        roi_gray = gray[coord[1]:coord[1]+coord[3], coord[0]:coord[0]+coord[2]]\n",
    "                        label, confidence = self.recognizer.predict(roi_gray)\n",
    "                        self.confidence_lst.append(confidence)\n",
    "                        \n",
    "                    name = \"mathcing 80% rectangle,    complete {:.1f}%\".format(len(self.confidence_lst)/100*100)\n",
    "                    cv2.putText(frame, name, (20, 20), font, 1,(255,0,0), stroke, cv2.LINE_AA)\n",
    "\n",
    "                    coord = self.size_filter(coords)\n",
    "                    cv2.rectangle(frame, (self.x, self.y), (self.x+self.w, self.y+self.h), (255,0,0), 2)\n",
    "\n",
    "                    if len(self.confidence_lst) == 100 :\n",
    "                        cThread = confidenceThread(self.confidence_lst)\n",
    "                        cThread.start()\n",
    "                        self.start_saving = True\n",
    "                        \n",
    "                        print(\"[{}] : step4 finished\".format(time.strftime(\"%Y/%m/%d %H:%M:%S\", time.localtime(time.time()))))\n",
    "                        print(\"\")\n",
    "                        \n",
    "                        self.start_register = False\n",
    "                        self.dialog.start = False\n",
    "                    \n",
    "            else :\n",
    "                self.step = [1]\n",
    "                read, frame = self.video_capture.read()\n",
    "                frame = cv2.resize(frame, WH)\n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "                h, w, c = HWC \n",
    "            \n",
    "                name = \"ready for register,place at center of sreen\"\n",
    "                cv2.putText(frame, name, (20, 20), font, 1,(255,0,0), stroke, cv2.LINE_AA)\n",
    "                cv2.circle(frame, (w//2, h//2), 3, (255,0,0), -1)\n",
    "\n",
    "            q_img = QImage(frame, w, h, w*c, QImage.Format_RGB888)\n",
    "            pixmap = QPixmap.fromImage(q_img)\n",
    "            pixmap_image = QPixmap(pixmap)\n",
    "\n",
    "            self.imageLabel.setPixmap(pixmap_image)\n",
    "            \n",
    "                \n",
    "    def check_include_center(self, coord, w, h) :\n",
    "        if (coord[0] < (w//2) < (coord[0]+coord[2])) and  (coord[1] < (h//2) < (coord[1]+coord[3])) :\n",
    "            return True\n",
    "        else :\n",
    "            return False\n",
    "\n",
    "    def check_overlap(self, coord) :\n",
    "        r1 = (self.x , self.y-self.h, self.x+self.w, self.y)\n",
    "        r2 = (coord[0] , coord[1]-coord[3], coord[0]+coord[2], coord[1])\n",
    "        \n",
    "        dx = min(r1[2], r2[2]) - max(r1[0], r2[0])\n",
    "        dy = min(r1[3], r2[3]) - max(r1[1], r2[1])\n",
    "        area = dx*dy\n",
    "        \n",
    "        if (dx>=0) and (dy>=0) and (area/(self.w*self.h) >= 0.8) :\n",
    "            return area/self.w*self.h, True\n",
    "        else :\n",
    "            if dx*dy<= 0 :\n",
    "                area = 0\n",
    "            return 0, False \n",
    "                \n",
    "    def detect(self, gray, frame, color):\n",
    "        faces = self.face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "        face = self.size_filter(faces)\n",
    "        roi_color = []\n",
    "        eye = False\n",
    "        \n",
    "        for (x,y,w,h) in face : \n",
    "            cv2.rectangle(frame, (x,y), (x+w, y+h), color, 2)\n",
    "\n",
    "            roi_gray = gray[y:y+h, x:x+w]\n",
    "            roi_color = frame[y:y+h, x:x+w]\n",
    "            \n",
    "            eyes = self.eyes_cascade.detectMultiScale(roi_gray, 1.1, 3)\n",
    "            if len(eyes) == 0:\n",
    "                eye = False\n",
    "            else :\n",
    "                eye = True\n",
    "                    \n",
    "        if len(face) == 0 :\n",
    "            flag = False\n",
    "        else :\n",
    "            flag = True\n",
    "            \n",
    "        coord = face\n",
    "        return flag, roi_color, coord , eye\n",
    "        \n",
    "    def set_rectangle(self, coord_lst) :\n",
    "        x_lst = [coord[0] for coord in coord_lst]\n",
    "        y_lst = [coord[1] for coord in coord_lst]\n",
    "        w_lst = [coord[2] for coord in coord_lst]\n",
    "        h_lst = [coord[3] for coord in coord_lst]\n",
    "\n",
    "        x = int(sum(x_lst)/len(x_lst))\n",
    "        y = int(sum(y_lst)/len(y_lst))\n",
    "        w = int(sum(w_lst)/len(w_lst))\n",
    "        h = int(sum(h_lst)/len(h_lst))\n",
    "        \n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.w = w\n",
    "        self.h = h \n",
    "        \n",
    "    def size_filter(self, coords) :\n",
    "        if len(coords) == 0 :\n",
    "            return []\n",
    "        \n",
    "        size = 0 \n",
    "        for coord in coords :\n",
    "            now = coord[2]*coord[3]\n",
    "            if now > size :\n",
    "                size = now\n",
    "                best_coord = coord\n",
    "\n",
    "        return [best_coord]\n",
    "    \n",
    "class trainThread(QThread) :\n",
    "    def __init__(self, imgs, count):\n",
    "        QThread.__init__(self)\n",
    "        self.imgs = imgs\n",
    "        self.count = count\n",
    "        \n",
    "    def __del__(self):\n",
    "        self.wait()\n",
    "\n",
    "    def run(self):\n",
    "        self.save_and_train()\n",
    "        \n",
    "    def setRecognizer(self, recognizer) :\n",
    "        self.recognizer = recognizer\n",
    "        \n",
    "    def setStep(self, step) :\n",
    "        self.step = step\n",
    "    \n",
    "    def setFlag(self, flag) :\n",
    "        self.finish_saving = flag\n",
    "    \n",
    "    def setCoord(self, coord) :\n",
    "        self.coord = coord\n",
    "        \n",
    "    def text_rectangle(self, coords) :\n",
    "        result = []\n",
    "        for lst in coords :\n",
    "            result.append(\", \".join([str(x) for x in lst]))\n",
    "            \n",
    "        return result\n",
    "        \n",
    "    def save_and_train(self) :\n",
    "        for idx, img in enumerate(self.imgs) :\n",
    "            cv2.imwrite(\"./data/register/registered_png/register_{}.png\".format(idx), img, [])\n",
    "        \n",
    "        labels = self.make_labels(self.imgs)\n",
    "        grays = self.making_gray(self.imgs)\n",
    "        \n",
    "        self.recognizer.train(grays[10:], labels[10:])\n",
    "        self.recognizer.save(\"./data/register/registered_info/train1.yml\")\n",
    "        \n",
    "        coord = self.text_rectangle(self.coord)\n",
    "        with open(\"./data/register/registered_info/rectangle_coord.txt\", \"w\") as f:\n",
    "            f.write(\"\\n\".join(coord))\n",
    "            \n",
    "        cnt = [\", \".join(x) for x in self.count]\n",
    "        with open(\"./data/register/registered_info/count.txt\", \"w\") as f:\n",
    "            f.write(\"\\n\".join(cnt))\n",
    "        \n",
    "        self.finish_saving[0] = True\n",
    "        self.quit()\n",
    "        \n",
    "    def make_labels(self, images) :\n",
    "        labels = []\n",
    "\n",
    "        length = len(images)\n",
    "        for idx in range(length) :\n",
    "            labels.append(1)\n",
    "\n",
    "        return np.array(labels)\n",
    "        \n",
    "    def making_gray(self, images) :\n",
    "        result = []\n",
    "\n",
    "        for image in images :\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            result.append(gray)\n",
    "\n",
    "        return result\n",
    "    \n",
    "class confidenceThread(QThread) :\n",
    "    def __init__(self, confidence):\n",
    "        QThread.__init__(self)\n",
    "        self.confidence = confidence\n",
    "        \n",
    "    def __del__(self):\n",
    "        self.wait()\n",
    "\n",
    "    def run(self):\n",
    "        self.save()\n",
    "        \n",
    "    def save(self) :\n",
    "        with open(\"./data/register/registered_info/confidence.txt\", \"w\") as f:\n",
    "            f.write(\"\\n\".join([str(conf) for conf in self.confidence]))\n",
    "            \n",
    "        with open(\"./data/register/registered_info/train_datetime.txt\", \"w\") as f:\n",
    "            f.write(str(time.strftime(\"%Y/%m/%d %H:%M\", time.localtime(time.time()))))\n",
    "\n",
    "        print(\"-\"*90)\n",
    "        print(\"[{}] : train and saving are finished\".format(time.strftime(\"%Y/%m/%d %H:%M:%S\", time.localtime(time.time()))))\n",
    "        print(\"-\"*90)\n",
    "        print(\"\")\n",
    "        \n",
    "        self.quit()\n",
    "###############################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################################################\n",
      "[2019/01/24 16:04:27] : program start\n",
      "############################################################ \n",
      "\n",
      "############################################################\n",
      "[2019/01/24 16:04:30] : 'student100' try to login\n",
      "[2019/01/24 16:04:30] : 'student100' success to login\n",
      "############################################################ \n",
      "\n",
      "############################################################\n",
      "[2019/01/24 16:04:31] : camera is conntected\n",
      "############################################################ \n",
      "\n",
      "############################################################\n",
      "[2019/01/24 16:04:32] : fail to register -- ready for register\n",
      "############################################################ \n",
      "\n",
      "############################################################\n",
      "[2019/01/24 16:04:34] : try to register\n",
      "dialog size has (480, 360)\n",
      "############################################################ \n",
      "\n",
      "############################################################\n",
      "[2019/01/24 16:04:35] : start register\n",
      "############################################################ \n",
      "\n",
      "[2019/01/24 16:04:35] : step1 start\n",
      "[2019/01/24 16:04:38] : step1 finished\n",
      "[2019/01/24 16:04:38] : step2 start\n",
      "[2019/01/24 16:04:53] : step2 finished\n",
      "[2019/01/24 16:04:53] : step3 start\n",
      "[2019/01/24 16:04:54] : step3 finished\n",
      "[2019/01/24 16:04:54] : step4 start\n",
      "[2019/01/24 16:05:03] : step4 finished\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "[2019/01/24 16:05:03] : train and saving are finished\n",
      "------------------------------------------------------------------------------------------\n",
      "\n",
      "############################################################\n",
      "[2019/01/24 16:05:06] : success to register\n",
      "############################################################ \n",
      "\n",
      "\n",
      "############################################################\n",
      "[2019/01/24 16:05:52] : (2) program stop\n",
      "############################################################ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "class mainWindow(QMainWindow) :\n",
    "    def __init__(self) :\n",
    "        QMainWindow.__init__(self)\n",
    "        self.setWindowTitle(\"PyQt & openCV demo3\")\n",
    "        self.resize(300,200)\n",
    "        \n",
    "        self.main_widget = BeforeLogin()\n",
    "        self.setCentralWidget(self.main_widget)\n",
    "        \n",
    "    def closeEvent(self, event) :\n",
    "        reply = QMessageBox.question(self, 'Message',\"Are you sure to quit?\", \n",
    "                                           QMessageBox.Yes, QMessageBox.No)\n",
    "\n",
    "        if reply == QMessageBox.Yes:\n",
    "            if self.main_widget.token :\n",
    "                self.start = False\n",
    "                \n",
    "                if self.main_widget.afterLoginWidget.isDialog :\n",
    "                    self.main_widget.afterLoginWidget.registerDialog.close()\n",
    "                \n",
    "                self.main_widget.afterLoginWidget.video_capture.release()\n",
    "                self.main_widget.afterLoginWidget.detectionThread.quit()\n",
    "            event.accept()\n",
    "        else:\n",
    "            event.ignore()\n",
    "\n",
    "        \n",
    "        event.accept()\n",
    "        \n",
    "def main():\n",
    "    app = QApplication([])\n",
    "    main_window = mainWindow()\n",
    "    main_window.show()\n",
    "    \n",
    "    try :\n",
    "        sys.exit(app.exec_())\n",
    "        \n",
    "        print(\"#\"*60)\n",
    "        print(\"[{}] : (1) program stop\".format(time.strftime(\"%Y/%m/%d %H:%M:%S\", time.localtime(time.time()))))\n",
    "        print(\"#\"*60, \"\\n\")\n",
    "        \n",
    "    except :\n",
    "        print(\"\")\n",
    "        print(\"#\"*60)\n",
    "        print(\"[{}] : (2) program stop\".format(time.strftime(\"%Y/%m/%d %H:%M:%S\", time.localtime(time.time()))))\n",
    "        print(\"#\"*60, \"\\n\")\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
